{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General:\n",
    "import tweepy           # Para consumir la API de Tweeter\n",
    "import pandas as pd     # Para análisis de datos\n",
    "import numpy as np      # Para cálculo numérico\n",
    "\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os.path\n",
    "\n",
    "import csv\n",
    "import json\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "import ast\n",
    "\n",
    "\n",
    "from gensim.utils import simple_preprocess ,tokenize\n",
    "from gensim.models  import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion de llamada a la api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_setup():\n",
    "    \"\"\"\n",
    "    Función de utilidad para configurar la API de Twitter\n",
    "    con las claves de acceso.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Autenticación y acceso usando claves:\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "    # Retornar API con autenticación:\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    return api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion de extraccion de los tweets publicados en un dia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_caller_csv(id_,star_year,start_month,star_day):\n",
    "       \n",
    "        extractor = twitter_setup() \n",
    "        u = extractor.get_user(id_)\n",
    "        private= u.protected\n",
    "        startdate = datetime.datetime(star_year,start_month,star_day)\n",
    "        end_date= datetime.datetime(star_year,start_month,star_day+1)\n",
    "        \n",
    "        if os.path.isfile(u.screen_name + '_tweets.csv') == True:\n",
    "            print('Archivo de tweets ya existe')\n",
    "            pass\n",
    "        else:\n",
    "        \n",
    "            if private == False:\n",
    "                try: \n",
    "\n",
    "                        name = u.screen_name  \n",
    "                        tweets = extractor.user_timeline(id=id_, count=200,tweet_mode= 'extended')\n",
    "                        if len(tweets) > 0: \n",
    "\n",
    "                            alltweet = []\n",
    "                            alltweet.extend(tweets)\n",
    "                            oldest = alltweet[-1].id - 1\n",
    "\n",
    "                            try:\n",
    "                                while len(tweets) > 0:\n",
    "\n",
    "                                        tweets = extractor.user_timeline(id= id_,count=200,tweet_mode= 'extended',max_id=oldest)\n",
    "                                        alltweet.extend(tweets)\n",
    "                                        oldest = alltweet[-1].id - 1\n",
    "                            except ConnectionError:\n",
    "                                print('ConnectionError')\n",
    "\n",
    "                            result = [[tweet.id, tweet.created_at, tweet.full_text] for tweet in alltweet if tweet.created_at>startdate and tweet.created_at < end_date]\n",
    "                            data= pd.DataFrame(result, columns=['id','date','text'])\n",
    "\n",
    "                            data.to_csv( name + '_tweets.csv', line_terminator='\\rn')\n",
    "                        else:\n",
    "                            data= pd.DataFrame(columns=['id','date','text'])\n",
    "\n",
    "                            data.to_csv( name + '_tweets.csv', line_terminator='\\rn')\n",
    "\n",
    "                except Error as e:\n",
    "                        print('Error en la creacion del archivo _tweets.csv del usuario:',id_)\n",
    "                        print(e)\n",
    "                        pass\n",
    "\n",
    "            else:\n",
    "                print('private user')\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función de extraccion de seguidores de twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor_follows(id_):\n",
    "    extractor= twitter_setup()\n",
    "    ids = []\n",
    "    u = extractor.get_user(id_)\n",
    "    name = u.screen_name\n",
    "    \n",
    "    try:\n",
    "        for page in tweepy.Cursor(extractor.followers_ids, id=id_).pages():\n",
    "            ids.extend(page)\n",
    "    except: ConnectionError     \n",
    "        \n",
    "    ids=pd.DataFrame(ids,columns=[name],dtype=object)\n",
    "    ids.to_csv(name + '_followers.csv',mode= 'a')\n",
    "    \n",
    "    return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función de extraccion de seguidores con nombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor_follows_with_name(id_):\n",
    "    extractor= twitter_setup()\n",
    "    ids = []\n",
    "    try:\n",
    "        u = extractor.get_user(id_)\n",
    "        name = u.screen_name\n",
    "        try:\n",
    "            for page in tweepy.Cursor(extractor.followers_ids, id=id_).pages():\n",
    "                ids.extend(page)\n",
    "            \n",
    "        except:\n",
    "                pass\n",
    "            \n",
    "        ids_dataframe=pd.DataFrame(ids,columns=[name],dtype=object)\n",
    "        ids_dataframe.to_csv(name + '_followers.csv',mode= 'a')\n",
    "        \n",
    "    except tweepy.TweepError as e: \n",
    "        print('Usuario_borrado')\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función de para guardar el diccionario de predicciones en un archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_to_file(dic,name):\n",
    "    f = open(name+'predict_dict.txt','w')\n",
    "    f.write(str(dic))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función de para abrir el diccionario de predicciones de un archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict_from_file(name):\n",
    "    f = open(name+'predict_dict.txt','r')\n",
    "    data=f.read()\n",
    "    f.close()\n",
    "    return ast.literal_eval(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lista):\n",
    "    \n",
    "    lista_limpia=[]\n",
    "    for i in lista:\n",
    "        if type(i) == str:\n",
    "            pass \n",
    "        else:\n",
    "            lista_limpia.append(i)\n",
    "            \n",
    "    \n",
    "    \n",
    "    if len(lista_limpia)== 0:\n",
    "        lista= 'None'\n",
    "    else:\n",
    "        lista= sum(lista_limpia)/len(lista_limpia)\n",
    "    \n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(texto):\n",
    "    global model_w2v\n",
    "    global model \n",
    "    maxlen=30\n",
    "    prediction_matrix=[]\n",
    "    a = simple_preprocess(texto)\n",
    "    prediction_matrix.append([ model_w2v.vocab[w].index for w in a if w in model_w2v.vocab])\n",
    "    prediction_matrix= pad_sequences(prediction_matrix, padding='post', maxlen=maxlen)\n",
    "    class_= model.predict_classes(prediction_matrix)\n",
    "    probability= model.predict_proba(prediction_matrix)\n",
    "    return int(class_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_dict_first_level(id_,star_year,start_month,star_day):\n",
    "    \n",
    "    \n",
    "    extractor= twitter_setup()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        u = extractor.get_user(id_)\n",
    "        name = u.screen_name\n",
    "        dt= pd.read_csv(name + '_followers.csv',index_col= 0)\n",
    "        #Declarar el diccionario de predicciones \n",
    "        dicts= {}\n",
    "        for i in dt[name]:\n",
    "            try:\n",
    "                user= extractor.get_user(i)\n",
    "                \n",
    "                if user.protected == False:\n",
    "                    #extraer tweets y guardarlos en un csv\n",
    "                    tweet_caller_csv(i,star_year,start_month,star_day)\n",
    "                    #Cargar el archivo con los tweets\n",
    "                    tweets= pd.read_csv(user.screen_name +'_tweets.csv',dtype= object)\n",
    "                    #Obtener el texto de los tweets\n",
    "                    tweets= tweets['text'].astype(str)\n",
    "\n",
    "                    #Bucle de predicciones\n",
    "                    predictions=[]\n",
    "                    for v in tweets:\n",
    "                        #introducir en un lista las predicciones de los tweets \n",
    "                        predictions.append(prediction(v))\n",
    "                    #obtener la media de las predicciones \n",
    "                    predictions_mean= Average(predictions)\n",
    "\n",
    "                    dicts[i]= predictions_mean\n",
    "\n",
    "                else:\n",
    "                    #el usuario es privado\n",
    "                    dicts[i] = 'Private_user'\n",
    "                    \n",
    "            except tweepy.TweepError as e: \n",
    "                print('Usuario_borrado')  \n",
    "        #Guardar el diccionario de predicciones en un archivo\n",
    "        \n",
    "        save_dict_to_file(dicts,name) \n",
    "   \n",
    "    except tweepy.TweepError as e: \n",
    "         print('Usuario_borrado')  \n",
    "        \n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_dicts_second_level(id_,star_year,start_month,star_day):\n",
    "    \n",
    "    extractor= twitter_setup()\n",
    "    u = extractor.get_user(id_)\n",
    "    name = u.screen_name\n",
    "    dt= pd.read_csv(name + '_followers.csv',index_col= 0)\n",
    "    \n",
    "    for i in dt[name]:\n",
    "        try:\n",
    "            user= extractor.get_user(i)\n",
    "            user_name= user.screen_name\n",
    "            print(user_name)\n",
    "            user_dt = pd.read_csv(user_name+'_followers.csv',index_col= 0)\n",
    "            #Declarar el diccionario de predicciones \n",
    "            dicts= {}\n",
    "            #Obtener el segundo nivel de usuarios\n",
    "            for z in user_dt[user_name]:\n",
    "                try:\n",
    "                    user_follower= extractor.get_user(z)\n",
    "                    print(user_follower.screen_name)\n",
    "                    #Es posible que el seguidor ya este en un diccionario de predicciones\n",
    "                    if os.path.isfile(user_follower.screen_name + '_followers.csv') == True:\n",
    "                        pass\n",
    "                    #Si no existe el archivo no estan realizadas las predicciones     \n",
    "                    else:    \n",
    "\n",
    "                        if user_follower.protected == False:\n",
    "                            #Extraer tweets y guardarlos en un csv\n",
    "                            tweet_caller_csv(z,star_year,start_month,star_day)\n",
    "                            #Cargar el archivo con los tweets\n",
    "                            tweets= pd.read_csv(user_follower.screen_name +'_tweets.csv',dtype= object)\n",
    "                            #Obtener el texto de los tweets\n",
    "                            tweets= tweets['text'].astype(str)\n",
    "\n",
    "                            #Bucle de predicciones\n",
    "                            predictions=[]\n",
    "                            for v in tweets:\n",
    "                                #Introducir en un lista las predicciones de los tweets \n",
    "                                predictions.append(prediction(v))\n",
    "                            #Obtener la media de las predicciones \n",
    "                            predictions_mean= Average(predictions)\n",
    "\n",
    "                            dicts[z]= predictions_mean\n",
    "\n",
    "                        else:\n",
    "                            #El usuario es privado\n",
    "                            print('usuario privado')\n",
    "                            dicts[z] = 'Private_user'\n",
    "                            \n",
    "                except tweepy.TweepError as e: \n",
    "                    print('Usuario_borrado')\n",
    "               \n",
    "            #Guardar el diccionario de predicciones en un archivo\n",
    "            save_dict_to_file(dicts,user_name)\n",
    "            \n",
    "        except tweepy.TweepError as e: \n",
    "                print('Usuario_borrado')                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_graph_constructor(id_,star_year,start_month,star_day):\n",
    "    extractor= twitter_setup()\n",
    "    u = extractor.get_user(id_)\n",
    "    name = u.screen_name\n",
    "    #cargar los nodos (ids unicos de los followers)\n",
    "    dt = pd.read_csv(name + '_followers.csv',index_col= 0)\n",
    "    \n",
    "    list_of_followers =[]\n",
    "    #extraemos todos los ids de los seguidores\n",
    "    for i in dt[name]:\n",
    "        if i == id_:\n",
    "            pass\n",
    "        else:\n",
    "            list_of_followers.append(i)\n",
    "            user = extractor.get_user(i)\n",
    "            df = pd.read_csv(user.screen_name + '_followers.csv',index_col=0)\n",
    "            for v in df[user.screen_name]:\n",
    "                if v == id_:\n",
    "                    pass\n",
    "                else:\n",
    "                    list_of_followers.append(str(v))\n",
    "    \n",
    "    #transformamos la lista de seguidores en una lista con valores unicos\n",
    "    nodes= unique(list_of_followers)\n",
    "    # borramos la lista de seguidores para ahorrar espacion en memoria\n",
    "    del list_of_followers\n",
    "    \n",
    "    #Declaramos la grafica y añadimos el primer nodo en color verde para identificarlo\n",
    "    g= Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "    \n",
    "    g.add_node(str(id_),label=name,color='#00ff1e')\n",
    "    \n",
    "    #Aplicamos las etiquetas de color en funcion de las predicciones para cada diccionario\n",
    "    dict1 = color_labels(name)\n",
    "    for i in dict1:\n",
    "        g.add_node(str(i),lable= i,color=dict1.get(i))\n",
    " \n",
    "    #Añadimos los seguidores de segundo nivel\n",
    "    for i in dt[name]:\n",
    "        user = extractor.get_user(i)\n",
    "        dicts = color_labels(user.screen_name)\n",
    "        for v in dicts:\n",
    "            g.add_node(str(v),lable= v,color=dicts.get(v))\n",
    "    \n",
    "    \n",
    "  \n",
    "    #Construimos los ejes \n",
    "    edges = []\n",
    "    new_nodes = []\n",
    "    for i in dt[name]:\n",
    "        if i == id_:\n",
    "            pass\n",
    "        else:\n",
    "            #añadimos los ejes del usuario principal\n",
    "            edges.append((str(id_),str(i)))\n",
    "            #añadimos los ejes de los seguidores \n",
    "            user = extractor.get_user(i)\n",
    "            df = pd.read_csv(user.screen_name + '_followers.csv',index_col=0)\n",
    "            for v in df[user.screen_name]:\n",
    "                if i == id_:\n",
    "                    pass\n",
    "                else:\n",
    "                    edges.append((str(i),str(v)))\n",
    "                    new_nodes.append(str(v))\n",
    "    \n",
    "    for y in new_nodes:\n",
    "        g.add_node(str(y),label=y, color= \"yellow\" )\n",
    "    \n",
    "    not_nodes = []\n",
    "    for i in nodes:\n",
    "        if i not in g.nodes:\n",
    "            not_nodes.append(i)\n",
    "    \n",
    "    edges_1=[]\n",
    "    for i in edges:\n",
    "        if i in not_nodes:\n",
    "            pass\n",
    "        else:\n",
    "            edges_1.append(tuple(i))\n",
    "            \n",
    "    \n",
    "    g.add_edges(edges_1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    g.show(name+'_sentiment_graph.html')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_labels(name):\n",
    "    #Carga el diccionario de predicciones del usuario dado\n",
    "    dicts = load_dict_from_file(name)\n",
    "    #Transformamos las predicciones realizadas en etiquitas de color\n",
    "    \n",
    "    print(type(dicts))\n",
    "    for i in dicts:\n",
    "        print(i)\n",
    "        if type(i)==str:\n",
    "            pass\n",
    "        else:\n",
    "            if type(dicts.get(i))== float:\n",
    "                if dicts.get(i) >0.2:\n",
    "                    dicts[i]= 'blue'\n",
    "                else:\n",
    "                    dicts[i]= 'red' \n",
    "            else:\n",
    "                if dicts.get(i)== 'None':\n",
    "                    dicts[i]= 'yellow'\n",
    "                elif dicts.get(i) == 'Private_user':\n",
    "                    dicts[i]= 'yellow'\n",
    "                else:\n",
    "                    pass #usuarios privados\n",
    "\n",
    "\n",
    "    return dicts\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(list1): \n",
    "  \n",
    "    \n",
    "    unique_list = [] \n",
    "        \n",
    "    for x in list1: \n",
    "        \n",
    "        if x not in unique_list and x!= 0: \n",
    "            unique_list.append(x) \n",
    "    \n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key='CTXchN99VNe7jl8MgZrE47AIm'\n",
    "consumer_secret= 'faQ0b0r6FyfblBIPfJe0k6qjlEEqbynVmghjaKuzZhjskggjFq'\n",
    "access_token = '1118494816105574401-JTGPAQhrSsvFSrd9O0eN03HkFVYjAK'\n",
    "access_secret = 'OWg6aPlumQPSlXFn2kAiQcByNFkWyse0nE9JgXxQlglnR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v = KeyedVectors.load_word2vec_format('SBW-vectors-300-min5.bin.gz', binary=True)\n",
    "model = pickle.load(open('Keras_model_with_stop_words_0_67acc.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor_all_followers(id_):\n",
    "    followers = extractor_follows_with_name(id_)\n",
    "    for i in followers:\n",
    "        extractor = twitter_setup() \n",
    "        u = extractor.get_user(i)\n",
    "        if os.path.isfile(u.screen_name + '_followers.csv') == True:\n",
    "            print('El archivo ' + u.screen_name + '_followers.cvs ya existe ') \n",
    "            pass\n",
    "        #Si no existe el archivo no estan realizadas las predicciones     \n",
    "        else:  \n",
    "            extractor_follows_with_name(i)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_network_twitter(id_,star_year,start_month,star_day):\n",
    "    extractor = twitter_setup() \n",
    "    \n",
    "    u = extractor.get_user(id_)\n",
    "    \n",
    "    if os.path.isfile(u.screen_name + '_followers.csv') == True:\n",
    "        print('Archivo encontrado iniciando prediction_dict_first_level')\n",
    "        prediction_dict_first_level(id_,star_year,start_month,star_day)\n",
    "        print('********************** Iniciando prediction_dict_second_level*****************')\n",
    "        prediction_dicts_second_level(id_,star_year,start_month,star_day)\n",
    "        print('-----------------------construyendo grafo-----------------------------')\n",
    "        sentiment_graph_constructor(id_,star_year,start_month,star_day)\n",
    "        \n",
    "    else:\n",
    "        print('Archivo no encontrado, recolectando followers')\n",
    "        extractor_all_followers(id_)\n",
    "        prediction_dict_first_level(id_,star_year,start_month,star_day)\n",
    "        prediction_dicts_second_level(id_,star_year,start_month,star_day)\n",
    "        sentiment_graph_constructor(id_,star_year,start_month,star_day)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "sentiment_network_twitter(924114887722364929,2020,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
